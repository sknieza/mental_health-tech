Congrats! You have reached the last Part of Sprint 1. As the final assignment, you will analyze the [Mental Health in the Tech Industry](https://www.kaggle.com/anth7310/mental-health-in-the-tech-industry) dataset. You will have to apply your knowledge in SQL, data analysis, and statistics to complete this task. We expect you to use your own judgment on how to select the most important avenues for exploration and perform the analysis. You will have to iteratively raise questions and use your data analysis skills to get answers.

As always, we do not expect this project to be perfect - there will be many more opportunities for you to apply your newly gained skills in the future. For now just use what you have learned and try your best!

### Objectives


- Practice performing EDA using Pandas.
- Practice visualizing data with Matplotlib & Seaborn.
- Practice estimating population parameters from sample data and communicating uncertainty around your insights.

### Requirements

- Download the dataset from [Kaggle.](https://www.kaggle.com/anth7310/mental-health-in-the-tech-industry)
- Query the dataset using sqlite. Only load the final dataset into a dataframe.
- Give an overview of the respondents of the survey. What is the sample size? What are the sociodemographic features of the respondents? Do you see any evidence of sampling bias?
- Perform exploratory data analysis. This should include creating statistical summaries and charts, checking for correlations and other relationships between variables, as well as other EDA elements.
- In a plot, report the [prevalence rate](https://en.wikipedia.org/wiki/Prevalence) of at least three mental diseases. Make sure to plot the confidence interval and provide its interpretation.
- Your notebook should be readable as a standalone document. In Markdown cells inform the reader of the questions you are trying to answer, and provide an interpretation of your results.
- Provide suggestions about how your analysis can be improved.

### Evaluation Criteria

- Adherence to the requirements. How well did you meet the requirements?
- Depth of your analysis. Did you just skim the surface or did you explore the dataset in depth?
- Visualization quality. Did you use charts effectively to visualize patterns in the data? Are your visualizations properly labeled? Did you use colors effectively? Did you adhere to the principle of proportional ink?
- Interpretation of results. Are you able to explain where the uncertainty in your estimates comes from? Are you able to measure and communicate that uncertainty in the form of a confidence interval?
- Code quality. Was your code well-structured? Did you use the appropriate levels of abstraction? Did you remove commented out and unused code? Did you adhere to PEP8? Did you adhere to SQL best practices?
- Code performance. Did you use the suitable algorithms and data structures to solve the problems?

### Project Review

During your project review, you should present your project as if talking to a manager and senior data scientist working in your team. You will have to find the right balance between explaining your insights intuitively and diving deeper into the technical aspects of your work. 

During a project review, you may get asked questions that test your understanding of covered topics. Here are some examples:
- What are the main types and subtypes of data?
- What are the main metrics of location? What are their main characteristics?
- What is variability? What are the main metrics of variability and their characteristics?
- What is a confidence interval? Why do we need it? Why is it not sufficient to just report the point estimates?
-What is correlation? How do we use it to analyze data?
- What is a contingency table?

For general project review guidelines, please refer to [this document.](https://turingcollege.atlassian.net/wiki/spaces/DLG/pages/537395951/Peer+expert+reviews+corrections)